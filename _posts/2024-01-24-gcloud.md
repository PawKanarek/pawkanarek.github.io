---
layout: post
title: "How to configure your first VM on Google Cloud TPU"
categories: gcloud
---

# Instructions
In this post I will guide you on how to create a new VM on `gcloud`, connect over ssh, and attach a persistent disk.

If you start your journey with cloud computing on Google Cloud I strongly recommend applying to Google TPU Research Cloud, doing so you will get free access to powerful machines, and they will give free money on startup. I was granted 1,316,12 PLN (that's more than $300) for 70 days. 

I got access to this machines: 
- 100 preemptible Cloud TPU v2-8 device(s) in zone us-central1-f
- 5 on-demand Cloud TPU v2-8 device(s) in zone us-central1-f
- 5 on-demand Cloud TPU v3-8 device(s) in zone europe-west4-a

You can apply here: https://sites.research.google/trc/about/

If Google accepted your request we can start with cloud configuration

At the beginning lets create a new clean conda environment named `gcloud` and specify we want python version 3.10.
```bash
$ conda create -n gcloud python=3.10
$ conda avtivate gcloud
```

# Instructions

1. Install gcloud
    - Docs: https://cloud.google.com/sdk/docs/install
	- Download zip from docs on your machine 
	- unzip and run interactive installer `./google-cloud-sdk/install.sh` 
	    - Login to your google account
	    - Select your project
	    - Setup your region (my is `europe-west4-a`)
2. Setup environment:
    - Docs: https://cloud.google.com/tpu/docs/setup-gcp-account
	- enable Cloud TPU API
	- enable TPU service account 
		- about: https://cloud.google.com/iam/docs/service-account-overview 
		- create your account with roles
			- TPU Admin
			- Storage Admin: Needed for accessing Cloud Storage
			- Logs Writer: Needed for writing logs with the Logging API
			- Monitoring Metric Writer: Needed for writing metrics to Cloud Monitoring
3. Create new TPU
	- Option 1. via `gcloud CLI`
        - use `gcloud compute tpus tpu-vm` 
        - to create new TPU VM v3-8 in europe-west4-a
            ```bash
            gcloud compute tpus tpu-vm create your-machine-name --zone=europe-west4-a --accelerator-type=v3-8 --version=tpu-vm-pt-2.0
            ```
        - to create v2-8 TPU in us-central1-f 
            ```bash
            gcloud compute tpus tpu-vm create your-maine-name --zone=us-central1-f --accelerator-type=v2-8 --version=tpu-vm-pt-2.0
            ```
        - Sometimes you need to be patient, as there is usually high demand when creating new VM machines, for most of time i was getting error: 
            ```bash
            ERROR: (gcloud.compute.tpus.tpu-vm.create) {
                "code": 8,
                "message": "There is no more capacity in the zone \"europe-west4-a\"; you can try in another zone where Cloud TPU Nodes are offered (see https://cloud.google.com/tpu/docs/regions) [EID: 0x1a50fbb229537bb]"
            }

            ```
    - Option 2. via web platform using `cloud.google.com`
        - I don't recommend it as I was getting all the time  "unknown error" without any meaningful information
	    - url https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm 
            - name: your-machine-name
            - zone: europe-west4-a
            - TPU settings: TPU vm architecture 
            - TPU type: v3-8
            - TPU software version: tpu-vm-pt-2.0 (for pytorch 2.0)
	            - You can read more about software versions: https://cloud.google.com/tpu/docs/supported-tpu-configurations#tpu_software_versions
4. Connect over ssh: 
    - If creation was successful then you can connect to your machine over ssh
        ```bash
        gcloud compute tpus tpu-vm ssh your-machine-name --zone=europe-west4-a
        ```
5. Create persistent disks
    - By default VM have only 100 GB disk space, so you probably would like to extend this size. You can do it by creating persistent disk 
        ```
        gcloud compute disks create your-disk-name --size 200 --zone europe-west4-a --type pd-balanced
        ```
    - this command will create new disk in your Google Cloud project named `sourceDisk: projects/yourprojectname/zones/europe-west4-a/disks/your-disk-name`
    - Be careful, this is not free. You can read more about pricing here: [disks-image-pricing](https://cloud.google.com/compute/disks-image-pricing)
6. Attach newly created disk to your VM
    - again use well known `gcloud CLI`
        ```
        gcloud alpha compute tpus tpu-vm attach-disk pawai-eu-1 --zone=europe-west4-a --disk=pawai-eu-disk-1 --mode=read-write
        ```
7. After attaching disk image to our machine we can log in over ssh to our machine (step 4.) and mount it so we can use it
    - Enter this commands on your VM
    ```bash
    sudo mount -o discard,defaults /dev/sdb /mnt/disks/persist
    sudo chmod a+w /mnt/disks/persist
    ```
    - If done right you should see this message `MOUNTED TO: `/mnt/disks/persist`
    - After that you can happily navigate to your storage 
    ```bash
    cd /mnt/disks/persist/ 
    ```

Docs: 
- add persisten disks https://cloud.google.com/compute/docs/disks/add-persistent-disk
- setup persistent disks: https://cloud.google.com/tpu/docs/setup-persistent-disk
- format & mount https://cloud.google.com/compute/docs/disks/format-mount-disk-linux



# Useful commands on fresh VM

### CONDA
Installing conda and creating new virtual environment
docs: https://docs.conda.io/projects/miniconda/en/latest/
```bash
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
conda create --name tpu python=3.10
conda activate tpu
```

### Diffusers
Install Hugging Face diffusers
docs: https://huggingface.co/docs/diffusers/installation
```bash
pip install diffusers["torch"] transformers
conda install -c conda-forge diffusers
```
I had an error, but i resolved it with installing exact version of `huggingface_hub``
```bash
pip install huggingface_hub==0.18
```

# PYTORCH
Instal pytorch for google TPU
docs: https://cloud.google.com/tpu/docs/run-calculation-pytorch
```bash
pip install torch~=2.1.0 torch_xla[tpu]~=2.1.0 torchvision -f https://storage.googleapis.com/libtpu-releases/index.html
```
Ensure that the PyTorch/XLA runtime uses the TPU.
```bash 
export PJRT_DEVICE=TPU
```
Note: you can also add this line at the end of `~/.bashrc`, otherwise this export will work only for single session

### JAX 
Instal JAX support
Docs: https://huggingface.co/blog/sdxl_jax
```bash
pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html
pip install flax
```

### GIT
Setup SSH key
docs: https://github.com/settings/keys
```bash
ssh-keygen -t ed25519 -C "your@mail.com"
eval "$(ssh-agent -s)"
ssh-add ~/.ssh/id_ed25519
cat ~/.ssh/id_ed25519.pub
```

### Hugging face
Instal Large File Support for git and clone Stable Diffusion XL model 
LFS Install
```
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs
git clone https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0
```


